{
  "cells": [
    {
      "metadata": {
        "_uuid": "71fff663eb9075c63db6ddd0904379ffbcdcad20",
        "_cell_guid": "88051c3d-4a44-4ec6-8adb-c1d38653e94d"
      },
      "cell_type": "markdown",
      "source": "# Data Science Challenge\n\n## Overview\n\nThe focus of this exercise is  on a field within machine learning called [Natural Language Processing](https://en.wikipedia.org/wiki/Natural-language_processing). We can think of this field as the intersection between language, and machine learning. Tasks in this field include automatic translation (Google translate), intelligent personal assistants (Siri), predictive text, and speech recognition for example.\n\nNLP uses many of the same techniques as traditional data science, but also features a number of specialised skills and approaches. There is no expectation that you have any experience with NLP, however, to complete the challenge it will be useful to have the following skills:\n\n- understanding of the python programming language, or similar third generation language.\n- understanding of basic machine learning concepts, i.e. supervised learning\n\n\n### Instructions\n\n1. Create a Kaggle account and `fork` this notebook.\n2. Answer each of the provided questions, including your source code as cells in this notebook.\n3. Provide us a link to your Kaggle notebook at your convenience.\n\n### Task description\n\nYou will be performing a task known as [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis). Here, the goal is to predict sentiment -- the emotional intent behind a statement -- from text. For example, the sentence: \"*This movie was terrible!\"* has a negative sentiment, whereas \"*loved this cinematic masterpiece*\" has a positive sentiment.\n\nTo simplify the task, we consider sentiment binary: labels of `1` indicate a sentence has a positive sentiment, and labels of `0` indicate that the sentence has a negative sentiment.\n\n### Dataset\n\nThe dataset is split across three files, representing three different sources -- Amazon, Yelp and IMDB. Your task is to build a sentiment analysis model using both the Yelp and IMDB data as your training-set, and test the performance of your model on the Amazon data.\n\nEach file can be found in the `../input` directory, and contains 1000 rows of data. Each row contains a sentence, a `tab` character and then a label -- `0` or `1`. \n\n**Notes**\n- This environment comes with a wide range of ML libraries installed. If you wish to include more, go to the 'Settings' tab and input the `pip install` command as required.\n- Suggested libraries: `sklearn` (for machine learning), `pandas` (for loading/processing data).\n- As mentioned, you are not expected to have previous experience with this exact task. You are free to refer to external tutorials/resources to assist you. However, you will be asked to justfify the choices you have made -- so make you understand the approach you have taken."
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nprint(os.listdir(\"../input\"))",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['readme.txt', 'amazon_cells_labelled.txt', 'yelp_labelled.txt', 'imdb_labelled.txt']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "!head \"../input/amazon_cells_labelled.txt\"",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "So there is no way for me to plug it in here in the US unless I go by a converter.\t0\r\nGood case, Excellent value.\t1\r\nGreat for the jawbone.\t1\r\nTied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!\t0\r\nThe mic is great.\t1\r\nI have to jiggle the plug to get it to line up right to get decent volume.\t0\r\nIf you have several dozen or several hundred contacts, then imagine the fun of sending each of them one by one.\t0\r\nIf you are Razr owner...you must have this!\t1\r\nNeedless to say, I wasted my money.\t0\r\nWhat a waste of money and time!.\t0\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "cbd1a4b1d16ce7db6def7b3b393b48618d7e4777",
        "_cell_guid": "387106cd-e89a-462f-b204-a91a73d12137"
      },
      "cell_type": "markdown",
      "source": "# Tasks\n### 1. Read and concatenate data into test and train sets.\n### 2. Prepare the data for input into your model."
    },
    {
      "metadata": {
        "_uuid": "78e68e8665b43c7e45625fa25cbae9999632ac8b",
        "_cell_guid": "4aa4c67a-7d4a-4baf-9108-7636f6514c9c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport random\n\nDATA_PATH = '../input'\nLABEL_MAP= {\n    1: 'positive',\n    0: 'negative'\n}\n\nTRAIN_FILES = {'yelp_labelled.txt', 'imdb_labelled.txt'}\nTEST_FILES = {'amazon_cells_labelled.txt'}\n\ndef iter_instances_at_path(path):\n    with open(path, 'rt') as f:\n        for i, line in enumerate(f):\n            sentence, label = line.split('\\t')\n            \n            # some very basic data norm and validation, break-out if it gets more complicated\n            sentence = sentence.strip()\n            label = int(label)\n            assert sentence\n            assert label in LABEL_MAP\n\n            yield {\n                'sentence': sentence,\n                'label': label,\n                'source': {\n                    'path': os.path.basename(path),\n                    'idx': i\n                },\n            }\n\nfiles = TRAIN_FILES.union(TEST_FILES)\nitems = [i for p in files for i in iter_instances_at_path(os.path.join(DATA_PATH, p))]\nprint(\"Read {:d} items from {:d} files...\".format(len(items), len(files)))",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Read 3000 items from 3 files...\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "3f9749941ff3b9f0b6b377cdfdad0de92fb5afd2",
        "_cell_guid": "1c9e1839-3504-4d77-88bb-702365c1547f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "items[:1]",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "[{'label': 0,\n  'sentence': 'So there is no way for me to plug it in here in the US unless I go by a converter.',\n  'source': {'idx': 0, 'path': 'amazon_cells_labelled.txt'}}]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "ff2b301dd19afb54a67bf51d062259cc949a1522",
        "_cell_guid": "20284b00-d12f-4ed3-83ca-4731033a9bc8",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import spacy\n\n# use spacy for the low-level cookie-cutter text processing (i.e. tokenization)\n# we will also make use of word vectors and dependency parse features\nnlp = spacy.load('en_core_web_lg')\n\ndef preprocess_item(item):\n    item['doc'] = nlp(item['sentence'])\n    return item",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dd99a9843b20385972016bd51d160450c840d8c8",
        "_cell_guid": "1dd94834-9376-4eca-9238-f512eebdba3d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from tqdm import tqdm_notebook as tqdm\nitems = [preprocess_item(i) for i in tqdm(items)]",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "A Jupyter Widget",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61bbdb984dc1407cb0431f4e973ffbcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c093abcdcbc3bc669777b2243db199edd0582bfb",
        "_cell_guid": "d76c8751-0117-47f1-8948-f82574c99296",
        "trusted": true
      },
      "cell_type": "code",
      "source": "items[:1]",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "[{'doc': So there is no way for me to plug it in here in the US unless I go by a converter.,\n  'label': 0,\n  'sentence': 'So there is no way for me to plug it in here in the US unless I go by a converter.',\n  'source': {'idx': 0, 'path': 'amazon_cells_labelled.txt'}}]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "69c6d7ea240a191abfaaf00574f09521944387d7",
        "_cell_guid": "a8240a39-7002-435b-ba45-ac859d209f7f"
      },
      "cell_type": "markdown",
      "source": "#### 2a: Find the ten most frequent words in the training set."
    },
    {
      "metadata": {
        "_uuid": "76627568142aa4580329dabaa52180dc55394b56",
        "_cell_guid": "fc50ab58-0ef4-4231-bfe4-452f55aa625d",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from collections import Counter",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8c2f4dc8614ede032e7f091584d33ac89d1e736b",
        "_cell_guid": "c57d7963-4d3e-44d0-a990-abe6b1c68d98",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# it really depends what we count as a \"word\"\ncounts = Counter()\nfor i in items:\n    if i['source']['path'] in TRAIN_FILES:\n        counts.update(t.text.lower() for t in i['doc'])\nprint(\"Most common tokens:\")\ncounts.most_common(10)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Most common tokens:\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "[('.', 1729),\n ('the', 1432),\n (',', 1012),\n ('and', 826),\n ('a', 669),\n ('i', 658),\n ('is', 517),\n ('of', 504),\n ('was', 501),\n ('it', 476)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "00c4af76c61b11aeac8fff422eff194cedf8a53f",
        "_cell_guid": "e21631f0-462c-49f7-a725-c25f62dd97b7",
        "trusted": true
      },
      "cell_type": "code",
      "source": "counts = Counter()\nfor i in items:\n    if i['source']['path'] in TRAIN_FILES:\n        for t in i['doc']:\n            if not t.is_stop and not t.is_punct and not t.lemma_ in nlp.Defaults.stop_words:\n                counts[t.lemma_] += 1\nprint(\"Most common non-stop, non-punctuation, lemmatized tokens:\")\ncounts.most_common(10)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Most common non-stop, non-punctuation, lemmatized tokens:\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "[('-PRON-', 2016),\n ('good', 230),\n ('movie', 212),\n ('film', 189),\n ('food', 127),\n ('bad', 126),\n ('place', 119),\n ('great', 115),\n ('like', 111),\n ('time', 103)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "9fc839577f6db6963a874419e4b277897ff21126",
        "_cell_guid": "c88c81fe-7c5f-4209-b001-ed98d17ff655"
      },
      "cell_type": "markdown",
      "source": "## Extract features"
    },
    {
      "metadata": {
        "_uuid": "fba871fc4fd2c2e51a2e58c08b245bcbf95802e8",
        "_cell_guid": "dfbebe25-6a06-470f-a217-86588a2c667c",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy\n\n# compute the cosine similarity between a pair of vectors\n# we will use this for word-vector features\ndef sim(a, b):\n    res = numpy.dot(a, b) / (numpy.linalg.norm(a) * numpy.linalg.norm(b))\n    if numpy.isnan(res):\n        return 0.\n    return res",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "16455db50b42112677fd0b725638bc1ac3ee00a3",
        "_cell_guid": "13f9fa22-bc45-42e4-88b6-b85ce6a1442f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "DELEX_POS_TAGS = {'PROPN', 'NOUN'}\ndef delexicalize(doc):\n    tks = []\n    for t in doc:\n        if t.pos_ in DELEX_POS_TAGS:\n            if not tks or tks[-1] != t.pos_:\n                tks.append(t.pos_)\n        else:\n            tks.append(t.lemma_)\n    return tks",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e675c5b52468293bb2d0c70fa8ecd5bcb2e66625",
        "_cell_guid": "8bbf72c2-efb1-470f-a91a-1040594a5fb1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def extract_bag_of_ngrams(item):\n    tokens = [t.lemma_.lower() for t in item['doc']]    \n    bigrams = ['|'.join(ngram) for ngram in zip(tokens, tokens[1:])]\n    for t in set(tokens + bigrams):\n        yield t, True\n\ndef extract_root_tokens(item):\n    for t in item['doc']:\n        if t.dep_ == 'ROOT':\n            yield t.lemma_, True\n\ndef extract_delex_ngrams(item):\n    tokens = [t for t in delexicalize(item['doc'])]\n    bigrams = ['|'.join(ngram) for ngram in zip(tokens, tokens[1:])]\n    for t in set(bigrams):\n        yield t, True\n\nfrom scipy.spatial.distance import cosine as cosine_distance\ngood = nlp('good').vector\nbad = nlp('bad').vector\ngv = good - bad\n\ndef extract_doc_vect_sim(item):\n    yield 'good', sim(item['doc'].vector, good)\n    yield 'bad', sim(item['doc'].vector, bad)\n    yield 'proj', sim(item['doc'].vector, gv)\n    \n    token_sims = [sim(t.vector, gv) for t in item['doc']]\n    yield 'max(proj)', max(token_sims)\n    yield 'min(proj)', min(token_sims)\n    yield 'direction', numpy.argmax(token_sims) > numpy.argmin(token_sims)\n\nFEATURES = [\n    ('bow', extract_bag_of_ngrams),\n    ('root', extract_root_tokens),\n    ('vect', extract_doc_vect_sim),\n    ('delex', extract_delex_ngrams)\n]\n\ndef get_features_for_item(item):\n    features = {}\n    for tag, extractor in FEATURES:\n        for key, value in extractor(item):\n            features[tag+':'+key] = value\n    return features\n\nfor i in tqdm(items):\n    i['features'] = get_features_for_item(i)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "A Jupyter Widget",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95232639ff1849f198b276685b1cbece"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in float_scalars\n  \n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "6f408cf9eb76c1d4f52cdbf14577ac32ad7feb2a",
        "_cell_guid": "601cca8b-52e3-4f5a-bdd2-cd3eabbc4101"
      },
      "cell_type": "markdown",
      "source": "### Split into train/dev/test"
    },
    {
      "metadata": {
        "_uuid": "bef9e10deb82a38a02e6997cfd41a3b2e2398f3f",
        "_cell_guid": "199b1f05-bd46-46b2-9004-efb9d5a4273c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train = [i for i in items if i['source']['path'] in TRAIN_FILES]\ntest = [i for i in items if i['source']['path'] in TEST_FILES]\n\nrandom.shuffle(train)\nrandom.shuffle(test)\n\n# in real task we might split off a separate dev-set here for model validation + feature engineering\n# e.g:\n# dev_split_idx = len(train)//4\n# dev, train = train[:dev_split_idx], train[dev_split_idx:]\n# print('Dev:', len(dev))\n\n# for the sake of this task, we'll just use cross-val for hyperparams selection and just note\n# that we're implicitly p-hacking the held-out eval when feature engineering\nprint('Train:', len(train))\nprint('Test', len(test))",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train: 2000\nTest 1000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "eb8b033dc4a841702ae52d4ec71e7718b3257dda",
        "_cell_guid": "f4cc399e-66c4-4bf7-a8e1-03711372c7b4"
      },
      "cell_type": "markdown",
      "source": "### 3. Train your model and justify your choices."
    },
    {
      "metadata": {
        "_uuid": "2d50c7559db0e49ac5285cbb0bffe99f50b3ef04",
        "_cell_guid": "64b3eb73-a97a-4468-a6a0-20e9090c30c1",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def items_to_dataset(items):\n    X, Y = [], []\n    for i in items:\n        X.append(i['features'])\n        Y.append(i['label'])\n    return X, Y\ntrain_X, train_Y = items_to_dataset(train)\ntest_X, test_Y = items_to_dataset(test)",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1a128a28c02359118e3f01160fdff293531e4cc8",
        "_cell_guid": "15054516-cd79-4593-aeef-e06d76e10981",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ngrid = {\n    \"n_estimators\": [25, 100, 200],\n    \"max_depth\": [3, None],\n}\n\nclf = Pipeline((\n    ('vectorizer', DictVectorizer()),\n    ('classifier', GridSearchCV(RandomForestClassifier(), param_grid=grid, cv=5))\n))\n\nmodel = clf.fit(train_X, train_Y)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "55b706bdb6c338562c3ae8d2eb03ac0c502c96d2",
        "_cell_guid": "099ca5c8-a193-44cd-a780-161a5f7bdd8b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.steps[-1][1].best_estimator_",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "f4eeecd64b54cc05098affe6cca4c40204af8ecf",
        "_cell_guid": "1a5840b2-c84c-42f6-9fc9-4fed64e48298"
      },
      "cell_type": "markdown",
      "source": "### 4. Evaluate your model using metric(s) you see fit and justify your choices."
    },
    {
      "metadata": {
        "_uuid": "500f34cbb0b2af52e5dfbf079a127a87f8289efe",
        "_cell_guid": "d8f5ec71-940e-481f-b411-c303df25d035",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score\n\ny_pred = model.predict(test_X)\nprint('Accuracy:', accuracy_score(test_Y, y_pred))",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy: 0.855\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b2202c3e622e59ace48882d0346be24d2bec2608",
        "collapsed": true,
        "_cell_guid": "c40efaf6-060e-4494-a40b-5ce9ffacab86",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# to calculate a bootstrapped ci we just iteratively resample instances\n# with replacement then look at the distribution of scores for some metric (i.e. accuracy)\ndef compute_bootstrapped_ci(y_pred, y, ci, n_samples=10000):\n    y, y_pred = numpy.array(y), numpy.array(y_pred)\n\n    scores = []\n    for _ in range(n_samples):\n        idxs = numpy.random.randint(len(y_pred), size=len(y_pred))\n        scores.append(accuracy_score(y[idxs], y_pred[idxs]))\n\n    bounds = (100-ci)/2\n    return numpy.percentile(scores, [bounds, 100-bounds])",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "062b99a88d85d9801558795c7b628798d7eb512e",
        "_cell_guid": "835dfb24-018b-4ae4-bf62-d50ada1ab7e0",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Confidence intervals for ACC:\")\nprint(\"95%:\", compute_bootstrapped_ci(y_pred, test_Y, 95))\nprint(\"99%:\", compute_bootstrapped_ci(y_pred, test_Y, 99))",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Confidence intervals for ACC:\n95%: [0.833 0.876]\n99%: [0.826 0.883]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "e676def452e84b0a93e9f0ba3f917862593b619a",
        "_cell_guid": "baf7b513-b0ae-469d-911f-4ea80e7520ee",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from collections import defaultdict\nfrom sklearn.metrics import precision_recall_fscore_support\n\nmeasures = precision_recall_fscore_support(test_Y, y_pred, average=None)\n\n# let's turn these into a nice table for printing\nmeasure_map = ['precision', 'recall', 'fscore', 'support']\nclass_measures = defaultdict(dict)\nfor m, measure in enumerate(measures):\n    for c, result in enumerate(measure):\n        class_measures[LABEL_MAP[c]][measure_map[m]] = result\n\n# for some feature sets, pos/neg p/r will be unbalanced\nprint(''.rjust(30), ''.join(m.rjust(10) for m in measure_map))\nfor c, measures in class_measures.items():\n    print(c.rjust(30), ''.join('{:.3f}'.format(measures[m]).rjust(10) for m in measure_map))",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                                precision    recall    fscore   support\n                      negative      0.854     0.856     0.855   500.000\n                      positive      0.856     0.854     0.855   500.000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "cb71b9e54c7314eceb6485a6510953ebd7548da0",
        "_cell_guid": "3c187fe6-7e7e-4ea9-ae2a-d072e5d79bc9",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nfrom sklearn.metrics import precision_recall_curve\nimport matplotlib.pyplot as plt\nprecision, recall, _ = precision_recall_curve(test_Y, [p[1] for p in model.predict_proba(test_X)])\nplt.figure(figsize=(6, 6))\nplt.plot(recall, precision)\nplt.xlabel('Recall')\nplt.ylabel('Precision')",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "Text(0,0.5,'Precision')"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<matplotlib.figure.Figure at 0x7fc8103d9908>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIxKgUREYn5//Rox+9Kb8PZAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "41db279986ba738f0851a3e676109d62c1be03b3",
        "_cell_guid": "7fb5cc1c-566c-40c9-9947-5d1c83ed67ae"
      },
      "cell_type": "markdown",
      "source": "## Model introspection"
    },
    {
      "metadata": {
        "_uuid": "c8c0906a7b86f66c74639f8d27079f05e7a0179d",
        "_cell_guid": "7f84b27d-6b1c-4f4f-b8a0-593d11fd69c3",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# what are the most important features?\nselected_clf = model.steps[-1][1].best_estimator_\nfeature_importances = sorted(zip(selected_clf.feature_importances_, model.steps[0][1].get_feature_names()), reverse=True)\nfeature_importances[:10]",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "[(0.05427131273198408, 'vect:proj'),\n (0.04797502942057439, 'vect:min(proj)'),\n (0.03380696992352641, 'vect:max(proj)'),\n (0.023781211055738268, 'vect:bad'),\n (0.01279503359060074, 'bow:not'),\n (0.00900958138334652, 'vect:good'),\n (0.00723409893915622, 'bow:great'),\n (0.00636432365836536, 'bow:bad'),\n (0.004503404274126933, 'delex:be|not'),\n (0.004358828067519962, 'bow:love')]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "176ed7a9e6b963646562ce41ae73b4394f59f2af",
        "_cell_guid": "8609c5b4-c804-4c53-898c-9d0a5509a204"
      },
      "cell_type": "markdown",
      "source": "### Error analysis\n\nTo understand the mistakes made by the model, we consider instances where the model assigns a high liklihood to a label, but is wrong."
    },
    {
      "metadata": {
        "_uuid": "3a4284fa0b90d968962ebe93b185bc5199618a4a",
        "collapsed": true,
        "_cell_guid": "fbf62f45-8238-4859-af3b-300e02251f4f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "feature_importance_ranks = {k:i for i, (_, k) in enumerate(feature_importances)}",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "92f7a48d4d06decb27e155bce0e09b3382c9a4eb",
        "_cell_guid": "c1690fe9-9569-4cbe-877b-d1fbb38ccd4e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# for each mistake, we have lots of features but generally only need to see the most important ones to interpret decisions\ndef get_top_features(features, limit=10):\n    return sorted(features.keys(), key=lambda k: feature_importance_ranks.get(k, len(feature_importance_ranks)))[:limit]\n\nmistakes = []\nfor item, label, probs in zip(test, test_Y, model.predict_proba(test_X)):\n    if label != numpy.argmax(probs):\n        mistakes.append((numpy.max(probs), LABEL_MAP[item['label']], item['sentence'], get_top_features(item['features'])))\nsorted(mistakes, reverse=True)[:10]",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "[(0.98,\n  'negative',\n  'Excellent starter wireless headset.',\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'vect:good',\n   'vect:direction',\n   'bow:excellent',\n   'bow:.',\n   'delex:NOUN|.',\n   'bow:headset']),\n (0.95,\n  'positive',\n  'Because both ears are occupied, background is not distracting at all.',\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'bow:not',\n   'vect:good',\n   'delex:be|not',\n   'bow:be|not',\n   'vect:direction',\n   'bow:at']),\n (0.945,\n  'negative',\n  'The loudspeaker option is great, the bumpers with the lights is very ... appealing.',\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'vect:good',\n   'bow:great',\n   'vect:direction',\n   'bow:the',\n   'bow:.',\n   'bow:,']),\n (0.94,\n  'positive',\n  'This fixes all the problems.',\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'vect:good',\n   'vect:direction',\n   'bow:the',\n   'bow:.',\n   'bow:this',\n   'delex:the|NOUN']),\n (0.905,\n  'negative',\n  'Low Quality.',\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'vect:good',\n   'vect:direction',\n   'bow:.',\n   'delex:PROPN|.',\n   'bow:quality',\n   'bow:low']),\n (0.895,\n  'positive',\n  'I was able to do voice dialing in the car with no problem.',\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'vect:good',\n   'delex:no|NOUN',\n   'vect:direction',\n   'bow:no',\n   'bow:do',\n   'delex:-PRON-|be']),\n (0.87,\n  'positive',\n  \"My phone doesn't slide around my car now and the grip prevents my phone from slipping out of my hand.\",\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'bow:not',\n   'vect:good',\n   'bow:do|not',\n   'vect:direction',\n   'delex:do|not',\n   'bow:and']),\n (0.865,\n  'positive',\n  \"Gets a signal when other Verizon phones won't.\",\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'bow:not',\n   'vect:good',\n   'vect:direction',\n   'bow:.',\n   'bow:a',\n   'delex:a|NOUN']),\n (0.855,\n  'positive',\n  \"I've had no trouble accessing the Internet, downloading ringtones or performing any of the functions.\",\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'vect:good',\n   'delex:no|NOUN',\n   'vect:direction',\n   'bow:no',\n   'delex:NOUN|,',\n   'bow:-pron-']),\n (0.84,\n  'positive',\n  'They do not last forever, but is not overly expensive to replace.Easy to operate and the sound is much better than others I have tried.',\n  ['vect:proj',\n   'vect:min(proj)',\n   'vect:max(proj)',\n   'vect:bad',\n   'bow:not',\n   'vect:good',\n   'delex:be|not',\n   'bow:do|not',\n   'bow:good',\n   'bow:be|not'])]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "87a6daf6342c1f824ee127ff45b2ab6ce0d916ff",
        "collapsed": true,
        "_cell_guid": "1147537f-edb1-43ae-815c-0a20a7e35b42",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}